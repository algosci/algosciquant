{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\", size=\"6\">S&P 500 Market Prediction</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "### Goals\n",
    "\n",
    "One of the more exciting areas to apply machine learning and AI is to financial markets. This in fact is one of the very exciting applications for machine learning. [Economist, Machine Learning for Finance](#https://www.economist.com/news/finance-and-economics/21722685-fields-trading-credit-assessment-fraud-prevention-machine-learning). Our over-arching goal is to apply algorithms and machine learning to real-world problems through the use of software, therefore all the results developed herein are available in Github (**link**)  \n",
    "\n",
    "In this article we focus our efforts on the S&P 500. Investors are keenly interested in monitoring and anticipating market ups and downs in order to gain financial benefit. Additionally, they are interested in anticipating when the market will turn down form \"Bull\" to \"Bear\" or conversely turn up from \"Bear\" to \"Bull.\" This information allows the investor to guard against financial loss or gain during financial up markets. In this article we apply machine learning to the S&P 500. In a later article we will dive into specific stocks. \n",
    "\n",
    "\n",
    "### S&P Trade Strategy\n",
    "\n",
    "For any problem we study as a data scientist, we first undrstand the business problem. In this case, the business problem is to create a predictive model that predicts the market S&P 500 movement so that the investor can take appropriate action. When it comes to the stock market, the key is to pick a trade strategy as discussed in this link https://www.dailyfx.com/forex/education/trading_tips/daily_trading_lesson/2012/07/10/How_to_build_a_trading_strategy.html. Below, we summarize the strategy assumed in this artilcle. \n",
    "\n",
    "In concept, our strategy is simple. Predict the price movement of the S&P 500 index up or down and execute a trade in order to optimize profitability. In addition to supporting a trading strategy, predicting the S&P up and down movements helps us understand the overall stock market. The strategy is summarized in the diagram below. Each day after the market closes, and before the next day's market is open, a predictive model receives inputs (feature variables) and outputs the predictor signal p_1. These feature variables are derived from the stock historical information and act as dependent variables, such as in linear regression and the output signal, p_1, is the dependent variable, output. If you own the stock then hold and if not buy. However, if the signal is -1 then this indicates sell. If you own the stock sell, but if you don't own the stock do not take any action, sit on cash. \n",
    "\n",
    "![Rendering preferences pane](./TradeStrategy.png)\n",
    "\n",
    "Several different predictive model types are employed including models generated from supervised learning employing Decision Tree classification model, Random Forest classification model, a heuristic model based on S&P market cycles and and hybrid models based on a combination of supervised learning models and market cycle parameters. Each of these is back tested in order to evaluate it's effectiveness during historical stock market periods.\n",
    "\n",
    "### Scope and Perspective\n",
    "* Discussion will be focused on results and with a light introduction of the software. The author is happy to converse offline (email) for the sake of answering questions, clarifications and constructive suggestions. \n",
    "* Intimate understanding of the softare is not necesary to understand this article. However, if you are interested in the software, this overview should provide the introduction and examples to get you started. \n",
    "* The article is not written from the perspective of a financial theorist, but instead from the pserspective of machine learning perspective and focused on the real-world application that demonstrates financial value. \n",
    "* This article is written in a Jupyter, Pythyon notebook, where each of the results and graphs is generated by actual Python software functions that exemplify how to apply Python and the algosciquant functions. If you are unfamiliar with notebooks, just think of them as a working environment where Python computer code is executed within code blocks (as exemplified in the article).\n",
    "\n",
    "### Overview\n",
    "\n",
    "We follow a typical data science process atuned to our financial prediction problem.\n",
    "  * Import data\n",
    "  * Study the data and get some intution \n",
    "  * Feature engineering\n",
    "  * Model generation and prediction \n",
    "  * Backtest\n",
    "\n",
    "The remainder of the article these topics will be discussed within the following sections.   \n",
    "\n",
    "&nbsp;&nbsp; **Section II**. &nbsp;  Notebook setup  \n",
    "&nbsp;&nbsp; **Section III**.&nbsp; Market cycles  \n",
    "&nbsp;&nbsp; **Section IV**. &nbsp; Features and Class Labels    \n",
    "&nbsp;&nbsp; **Section V**. &nbsp;   Model Training and Prediction    \n",
    "&nbsp;&nbsp; **Section VI**. &nbsp;  Back test    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# II. Notebook setup\n",
    "\n",
    "The first step in our analysis is to setup our Jupyter notebook, which consists of importing necessary Python packages, setting up the algosicquant library functions, defining a few variables and importing the S&P 500 market data. We will not review the Python imports here since they are well known packages. Below, we briefly discuss the remaining items.\n",
    "\n",
    "### Notebook Variables\n",
    "\n",
    "A few variables are defined, which will be used throughout the notebook. \n",
    "   * Test Start (test_s) - Date to begin reporting the market signal prediction\n",
    "   * Test End (test_e) - Last date for reporting market signal prediction\n",
    "   * Data Start Date (dateStartDate) - The S&P data begins in the year 1950. Dates prior to the dataStartDate will be dropped in order to improve processing time. For example, this is especially helpful for computation of the market cycles.\n",
    "\n",
    "### Algosciquant Library\n",
    "\n",
    "The \"algosciquant\" library is a custom set of functions specifically developed for the financial markets and stock prediction use case. It is freely available in Github (). We will provide a conceptual description of each of the key functions employed by this notebook in the bullets below and throughout the discussion. However, as previously mentioned, the main focus is the overall results and introduction to capabilities rather than in depth explanation of the software.\n",
    "\n",
    "    * Import from Google Finance and Intrinio\n",
    "\n",
    "    * Market Cycle\n",
    "\n",
    "    * ML Features and Class Lables \n",
    "\n",
    "    * Model Creation\n",
    "\n",
    "    * Confusion Matrix\n",
    "\n",
    "    * Prediction\n",
    "\n",
    "    * Back Testing\n",
    "\n",
    "    * Plotting convenience functions\n",
    "\n",
    "\n",
    "### S&P Data  \n",
    "\n",
    "The S&P data was downloaded from Yahoo. In this discussion we will not get into details about this process. We will discuss acquiring market data in separate post.\n",
    "* Read in S&P Data. lkfl;sdjf\n",
    "* This is all that is needed to get the notebook setup. \n",
    "\n",
    "\n",
    "### Observations\n",
    "\n",
    "Study the data and get some intuition\n",
    "\n",
    "While studying the S&P price movements and trends we notice strong correlation to Volatility and Moving Averages. Below we plot the S&P 3 graphs to illustrate\n",
    "* close pricg \n",
    "* 60-day and 12-day relative price trailing moving average\n",
    "* yearly volatility based on observation of 10, 50 and 120 days\n",
    "\n",
    "Later, will make use of these observations in order to create some heuristic prediction models. \n",
    "  \n",
    "![sdfsdfasdfsa](./sp_vlty_2000_2017428.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-table style --> \n",
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-table style --> \n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataStartDate =  2014-01-01 00:00:00 \n",
      "test_s =  2016-01-01 00:00:00 \n",
      "test_e =  2017-04-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# I. Notebook Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "%matplotlib inline\n",
    "%run algosciquant\n",
    "\n",
    "# Notebook Paramters\n",
    "test_s = dt.datetime(2016,1,1)      # 2016 for daily predictions, 2000, 1970, 1960\n",
    "dataStartDate=dt.datetime(2014,1,1) # 2014 for daily updates, 1950 for long term updates\n",
    "train_s = dt.datetime(1950,1,1)\n",
    "today = dt.datetime.today()\n",
    "#test_e = dt.datetime(today.year,today.month,today.day)\n",
    "test_e = dt.datetime(2017,4,28)\n",
    "print(\"dataStartDate = \",dataStartDate,'\\ntest_s = ',test_s,'\\ntest_e = ',test_e)\n",
    "\n",
    "# Read in S&P 500 Data\n",
    "dfsp = pd.read_csv('./stock_data/sp500.csv',index_col=0,parse_dates=True)\n",
    "dfsp = dfsp[dataStartDate:]\n",
    "\n",
    "# Plot the S&P Price\n",
    "\n",
    "plot=0\n",
    "if plot == 1: \n",
    "    plot_stock(dfsp,test_s,test_e,plot_variables=['close_price'],labels=['close_price'], figsize=[12,4])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Market Cycles\n",
    "\n",
    "### Computing Up and Down Market Cycles with *marketCycle()*\n",
    "\n",
    "Understanding S&P market cycles is key to developing intuition about the market. The alcosciquant *marketCycle()* function takes as input S&P historical prices and generates the up and down market cycles. The input and output parameters are described in detail within algosciquant.py. Here, we provide a brief summary. *MarketCycle()* will return two DataFrames, *dfmc* and *dfmcsummary*. \n",
    "\n",
    "MarketCylce() inputs\n",
    "\n",
    "  * *Mucdown* (input variable) - the percentage market down, measured from the previous high, at which time the market is declared to be a down market. As in the definition of a Bear Market, the official start of the down cycle is from the previous high. \n",
    "  * *Mdcup* (output variable) - the market cycle up percentage, from the previous low, at which time the market is declared to be an up market. As with a Bull Market, the cycle start point is at the previous low.  \n",
    "  \n",
    "*MarketCycle() outputs*\n",
    "\n",
    "* *Dfmc* is a DataFrame indexed by date (one entry for each market day) including several columns (\"parameters\") that characterize the market on the given day. Two parameters of importance to this analysis are *mcnr* and *mcupm*. \n",
    "* *Mcnr* - market cycle normalized return, normalized to zero at the start of each market up or down cycle.\n",
    "* *Mcupm* - markcet cycle up marker. along with a derived variable \"mcupm,\" which indicates the day that the market is detected to switch from up to down, (1 to 0) or visa versa and holds the state until the next switch. Below, we will employ this variable as a a heuristicly derived trade signal, \"buy\" or \"sell.\"\n",
    "* *Dfmcsummary* includes one row summarizing each up and each down market cycle. The summary includes the start day, end day and normalized return (up or down) from the start of the market cycle. \n",
    "\n",
    "### Market Cycles (Bull and Bear)\n",
    "\n",
    "Below we plot the Bull (Up 21% from market cycle low) and Bear (down, 20% from market high) market cycles of the S&P 500 from 1950 to 2017-04-28.  \n",
    "\n",
    "![sdfsdfasdfsa](./mc_2021.png)\n",
    "\n",
    "\n",
    "\n",
    "### Market Cycles Summary\n",
    "For reference we list the *dfmcsummary* data frame from 1950 to 04/28/2017, resulting from the inputs *mucdown* = 20 (down 20% from the market high), and *mdcup = 21% (21% up from the market low). This good match with the market cycles in our *dfmcsummary* (listed below) and the Bull and Bear market cycles reported in http://www.gold-eagle.com/article/history-us-bear-bull-markets-1929.\n",
    "\n",
    "Table: \n",
    "\n",
    "|mkt|startTime|endTime|startPrice|endPrice|mcnr|\n",
    "|---|---------|-------|----------|--------|----|\n",
    "|1.0|1950-01-03|1956-08-02|16.660000|49.639999|1.979592|\n",
    "|-1.0|1956-08-02|1957-10-22|49.639999|38.980000|-0.214746|\n",
    "|1.0|1957-10-22|1961-12-12|38.980000|72.639999|0.863520|\n",
    "|-1.0|1961-12-12|1962-06-26|72.639999|52.320000|-0.279736|\n",
    "|1.0|1962-06-26|1966-02-09|52.320000|94.059998|0.797783|\n",
    "|-1.0|1966-02-09|1966-10-07|94.059998|73.199997|-0.221773|\n",
    "|1.0|1966-10-07|1968-11-29|73.199997|108.370003|0.480465|\n",
    "|-1.0|1968-11-29|1970-05-26|108.370003|69.290001|-0.360616|\n",
    "|1.0|1970-05-26|1973-01-11|69.290001|120.239998|0.735315|\n",
    "|-1.0|1973-01-11|1974-10-03|120.239998|62.279999|-0.482036|\n",
    "|1.0|1974-10-03|1980-11-28|62.279999|140.520004|1.256262|\n",
    "|-1.0|1980-11-28|1982-08-12|140.520004|102.419998|-0.271136|\n",
    "|1.0|1982-08-12|1987-08-25|102.419998|336.769989|2.288127|\n",
    "|-1.0|1987-08-25|1987-12-04|336.769989|223.919998|-0.335095|\n",
    "|1.0|1987-12-04|2000-03-24|223.919998|1527.459961|5.821454|\n",
    "|-1.0|2000-03-24|2001-09-21|1527.459961|965.799988|-0.367708|\n",
    "|1.0|2001-09-21|2002-01-04|965.799988|1172.510010|0.214030|\n",
    "|-1.0|2002-01-04|2002-10-09|1172.510010|776.760010|-0.337524|\n",
    "|1.0|2002-10-09|2007-10-09|776.760010|1565.150024|1.014972|\n",
    "|-1.0|2007-10-09|2008-11-20|1565.150024|752.440002|-0.519254|\n",
    "|1.0|2008-11-20|2009-01-06|752.440002|934.700012|0.242225|\n",
    "|-1.0|2009-01-06|2009-03-09|934.700012|676.530029|-0.276206|\n",
    "|1.0|2009-03-09|2017-06-26|676.530029|2447.639893|2.617932|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataStartDate =  2014-01-01 00:00:00 \n",
      "test_s =  2016-01-01 00:00:00 \n",
      "test_e =  2017-04-28 00:00:00\n",
      "mcvariable = 2025\n"
     ]
    }
   ],
   "source": [
    "# II. Market Cycles\n",
    "\n",
    "# The code block gives a choice of computing the S&P 500 market cycles from the close_price market \n",
    "# data loaded in the previous step (\"dfsp\") or loading a DataFrame (\"dfmc\") of pre-computed (\"saved\") market cycles. \n",
    "\n",
    "%run algosciquant\n",
    "compute=0   # if compute is 1 then compute new market cycles, else load from saved file\n",
    "print(\"dataStartDate = \",dataStartDate,'\\ntest_s = ',test_s,'\\ntest_e = ',test_e)\n",
    "\n",
    "# Computer Market Cycles\n",
    "if compute==1:\n",
    "    dfmc,dfmcsummary=compute_market_cycle(dfsp,dataStartDate,test_e,mcdown_p=20,mcup_p=25)\n",
    "\n",
    "# Load Market Cycle files\n",
    "if compute == 0:\n",
    "    mcvariable='2025' # 2021, 2022, 2023, 2024, 2025\n",
    "    print('mcvariable =',mcvariable)\n",
    "    mc_filename='./data_jupyter_notebook/sp500_dfmc'+mcvariable+'_1950_2017-4-28.csv'\n",
    "    mcs_filename='./data_jupyter_notebook/sp500_dfmcs'+mcvariable+'_1950_2017-4-28.csv'\n",
    "    dfmc = pd.read_csv(mc_filename,index_col=0,parse_dates=True)\n",
    "    dfmcsumary = pd.read_csv(mcs_filename,index_col=0,parse_dates=True)\n",
    "    \n",
    "# Plot S&P 500 Market Cycle\n",
    "plot = 0\n",
    "if plot==1:\n",
    "    basic_plot(dfmc,dataStartDate,test_e,plot_variables=['mcnr','mcupm'],labels=['mcnr','mcupm'],\n",
    "                figsize=[12,3],loc='upper right',save_fig='mc_'+mcvariable+'.png')\n",
    "    \n",
    "summary=0\n",
    "if summary ==1:\n",
    "    print('dfmcsummary:\\n',dfmcsummary[['mkt','startTime','endTime','startPrice','endPrice','mcnr']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Features and Class Labels\n",
    "\n",
    "### ML Features\n",
    "\n",
    "In this section we generate machine learning features (input variables) and class labels necessary for training a predictive model, such as a Decision Tree or Random Forest, based on a supervised learning paradigm. The feature variables are listed as part of the code block output. In the table, we provide a brief description of machine learning feature varables, grouped by type of variable and provide a brief description.\n",
    "\n",
    "Table: ML Features\n",
    "\n",
    "|Feature Type and Description|  Feature Variables  |\n",
    "|:----------------------------|:------------|\n",
    "|Basic market variables | close_price, volume|\n",
    "|high and low relative to open |high_price_ropen , low_price_ropen|\n",
    "|Relative price change, 1 and 2 day. Relative price change, close_pricer = close_price[n-1]/close_price[n] -1| close_pricer_h1, close_pricer_h2 |\n",
    "|Relative volume change, 1 and 2 day. volumer = volume[n-1]/volume[n] -1|volumer_h1, volumer_h2|\n",
    "|Price trailing moving averages based on relative price change.| close_pricer_ma5,close_pricer_ma10, close_pricer_ma20, close_pricer_ma30, close_pricer_ma60, close_pricer_ma90, close_pricer_ma120 | \n",
    "|Volume trailing moving averages based on relelative volume variable |volumer_ma5, volumer_ma10, volumer_ma20, volumer_ma30,volumer_ma60, volumer_ma90,volumer_ma120|\n",
    "|Yearly volatility measured over n trailing days | vol_y_10, vol_y_50, vol_y_120 | \n",
    "| market cycle variables | mc2025, mcupm, mcnr, mucdown, mdcup |\n",
    "\n",
    "\n",
    "### Class labels N day future\n",
    "We employ an N-day forward looking prediction as described by some bright Stanford students in their machine learning class project (http://cs229.stanford.edu/proj2013/DaiZhang-MachineLearningInStockPriceTrendForecasting.pdf). The class labeling method works as follows. The class labels are derived from the stock market data, where for each day the class label either +1 or -1 corresponding to the closing price of the n-th day in the future relative to the current day. Suppose n = 3, then if the current day is Monday and stock closing price is \\$1 on Monday and the Thursday close price is \\$1.10 then the class label, for Monday training prediction, is +1. Furthermore, suppose that the Friday closing price is \\$0.90 then the class label is -1.\n",
    "\n",
    "![sdfsdfasdfsa](./mc_tr_summary.png)\n",
    "\n",
    "The graph below illustrates the accuracy (correct predictions divided by total predictions) on the y-axis  achieved by a Decision Tree (*dt*) and Random Forest (*rf) prediction models versus the *nday* future prediction on the x-axis. The predictions occured over the dates 2014-01-01 to 2017-04-28 with the Feature variables listed in the table above. We will discuss training prediction in a little more detail in the following section. The key point here is to observe that the prediction accuracy improves as *nday* varies from 1 to larger number of days into the future. In fact 1 day into the future the accuracy is very poor. We find *ndays* set to 43 leads to good prediction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ML features\n",
      "Index(['close_pricer', 'volumer', 'close_price', 'volume', 'high_price_ropen',\n",
      "       'low_price_ropen', 'close_pricer_h1', 'close_pricer_h2',\n",
      "       'close_pricer_ma5', 'close_pricer_ma10', 'close_pricer_ma20',\n",
      "       'close_pricer_ma30', 'close_pricer_ma60', 'close_pricer_ma90',\n",
      "       'close_pricer_ma120', 'volumer_h1', 'volumer_h2', 'volumer_ma5',\n",
      "       'volumer_ma10', 'volumer_ma20', 'volumer_ma30', 'volumer_ma60',\n",
      "       'volumer_ma90', 'volumer_ma120', 'vol_y_10', 'vol_y_50', 'vol_y_120',\n",
      "       'mc2025', 'mcupm', 'mcnr', 'mucdown', 'mdcup'],\n",
      "      dtype='object')\n",
      "Truth t_n\n",
      "Index(['close_price', 't_n'], dtype='object')\n",
      "nrows =  756 null_rows =  120\n",
      "data start date = 2014-01-01 00:00:00 , start date = 2016-01-01 00:00:00 , end date = 2017-04-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# III. Features and Class Labels\n",
    "%run algosciquant\n",
    "\n",
    "# ML Features\n",
    "dfML=mlSpFeatures(dfsp,dfmc,mcvariable,dataStartDate,test_e)\n",
    "\n",
    "print(\"\\nML features\")\n",
    "print(dfML.columns)\n",
    "\n",
    "# Class Labels\n",
    "nday=43\n",
    "dfT= ndayTruth(dfsp.loc[dataStartDate:, ['close_price']], nday,tvariable='close_price')\n",
    "print('Truth t_n')\n",
    "print(dfT.columns)\n",
    "\n",
    "# Null Rows\n",
    "s=dt.datetime(1952,6,1)\n",
    "e=dt.datetime(2017,1,1)\n",
    "nullrows=sum([True for idx,row in dfML.loc[s:e].iterrows() if any(row.isnull())])\n",
    "nrows=len(dfML.loc[s:e])\n",
    "print(\"nrows = \",nrows,\"null_rows = \",nullrows)\n",
    "\n",
    "print('data start date =',dataStartDate, ', start date =',test_s,', end date =',test_e) \n",
    "\n",
    "plot=0\n",
    "if plot ==1:\n",
    "    fig = plt.figure()\n",
    "    # close_price\n",
    "    subplot_stock(fig,dfsp,311,test_s,test_e,plot_variables=['close_price'],\n",
    "                  labels=['close_price'],figsize=[12,6],loc='lower right',save_fig='')\n",
    "    #  moving average\n",
    "    subplot_stock(fig,dfML,312,test_s,test_e,plot_variables=['close_pricer_ma120','close_pricer_ma60'],\n",
    "                  labels=['close_pricer_ma120','close_pricer_ma60'],figsize=[12,6],loc='lower right')\n",
    "    #  volatility    \n",
    "    f3=fig.add_subplot(313)\n",
    "    subplot_stock(fig,dfML,313,test_s,test_e,plot_variables=['vol_y_10','vol_y_50','vol_y_120'],\n",
    "                  labels=['vlty_w10','vlty_w50','vlty_w120'],figsize=[12,6],loc='upper right',ncol=3,\n",
    "                  save_fig='sp_vlty_'+str(test_s.year)+'_'+str(test_e.year)+str(test_e.month)+str(test_e.day)+'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Model Training and Prediction\n",
    "\n",
    "\n",
    "### Training and Prediction Method\n",
    "\n",
    "The training and prediction follows a batch learning paradigm, whereby the predictive model is trained offline and offers a prediction. The model is trained over a training window of *train_days* days in the past. In the case of a Decision Tree model, *train_days* is set to 400 days. Each day the model is trained and predicts the market will be up or down *ndays* days into the future. The next day, the training window slides forward by 1 market day, again the model is trained and a prediction is made *n* trading days into the future. This cycle is summarized in the diagram below.\n",
    "\n",
    "<div markdown style=\"float:left\" {margin-left: 0 !important;}>  \n",
    "![sdfsdfasdfsa](./sp_ml_tp_strategy.png)\n",
    "\n",
    "The diagram, below describes this process in a bit more detail. In order to predict on day *k* + *ndays*, prior to market open, the prediction is made on day *k* with features from day *k*, after market close. The model is trained with a training set including features from *k*-*train_days* to *k* and class labels from day *k* - *ndays* - *train_days* - 1 to *k* + *ndays* -1. The model prediction performance and trade performance can be tested by saving the predictions as the training and prediction are performed over a historical market period. These saved predictions are then compared to the actual market behavior. \n",
    "\n",
    "<div markdown style=\"float:left\" >  \n",
    "![sdfsdfasdfsa](./tr_pred_days.png)\n",
    "\n",
    "### Training Set Example\n",
    "Let's take a more specific example. Suppose *ndays* = 1 and *train_days* = 2 and we want a buy or sell prediction for Tuesday, January 10, 2017 at market open. Also, suppose the training features consist of only 1 item, close price, where the close prices are  \n",
    "\n",
    "  * Thursday, January 5, close_price = $1.00  \n",
    "    \n",
    "  * Friday, January 6, close_price =  $1.10  \n",
    "    \n",
    "  * Monday, January 9, close_price =  $1.00  \n",
    "\n",
    "We train the model with features from Thursday and Friday (2 days), and class labels derived at Friday and Monday, market close. The table below lists the example training set with features X, labels Y and some description of these variables. \n",
    "\n",
    "<sp>  \n",
    "<center>Table: Example training set:  featuers X and labels Y, *ndays* = 1, *train_days* = 2 for prediction Tuesday, Jan 10, 2017 at market open.</center>\n",
    "\n",
    "|X (close price)|Y (label)|features description|label description (market up or down, 1 day in the future)|\n",
    "|---|---|:---|:---|\n",
    "|\\$1.10| -1 |close price, Friday, Jan 6, at market close | sign (close price, Monday, Jan 9, at market close - close price Friday, Jan 6, market close) |\n",
    "|\\$1.00| 1 |close price, Thursday, Jan 5, at market close | sign (close price, Friday, Jan 6, at market close - close price Thursday, Jan 5, market close) |\n",
    "\n",
    "### Model\n",
    "\n",
    "The supervised learning model is specified in the *model* parameter. Several models are preconfigured including: Decision Tree (*model*='DT'), Random Forest (model='RF'), Suport Vector Machine (model='SVM'), Logistic Regression (model='LR'), K Nearest Neighbor (model='KNN'), Naive Bayes ('NBB'), XG Boost (model='XG'). Two models were found very useful for this study. The Decision Tree trains quickly and gives good performance comparable to the best models and thus is quite useful, especially for initial evaulation and iteration. The Random Forest provides consistently the best overall performance though the training and prediction (for back testing) is much slower, especially when executed over decades. Below is a summary of the \n",
    "\n",
    "Decision Tree - There are approximately 252 trading days in a year so this corresponds to approximately 2.5 years.\n",
    "\n",
    "Random Forest -  There are approximately 252 trading days in a year so this corresponds to approximately 2.5 years.\n",
    "\n",
    "\n",
    "### Predictor signals\n",
    "\n",
    "A software object that can estimate some parameters based on a dataset is called an estimator. Similarly, an estimator that predicts behavior into the future based on historical data is a predictor. The Machine Learned model (code block below) outputs several predictors. In the next section (Section VI. Backtest) each of the predictors is described in more detail. In order to understand the our prediction model predictors, below we desicribe three of predictors generated the model: p, mc2025 and mc2025v. \n",
    "\n",
    "A few columns of the prediction output dataframe (dfTR) are listed below for the purpose of aiding the discussion. The last prediction date is (test_e = April 28, 2017), which is a prediction for the next market day. Future predictions for prior days  can be compared to actual market behavior in order to test the predictive performance.  The prediction corresponding to a given day is contained in the 'p' column and this is compared to the 't' column. For example, on 2017-04-27, *p* compared to *t*. Other predictors, such as *mc2025* and *mc2025v* are also compared to the *t* column in order assess their predictive performance. \n",
    "\n",
    "|date| close_price |t_n |p_n |t |p |t_1|p_1 |\n",
    "|----|---|--- |---|--|---|---|--  |---|\n",
    "|2017-04-24 |2374.15 | 1  | 0 |t |1.0 |1 | 1.0 | \n",
    "|2017-04-25 |2388.61   | 1  | 0 |1| 1.0 |-1|-1.0 |\n",
    "|2017-04-26 |2387.45  |-1  | 0 | -1 | -1.0|1| 1.0 | \n",
    "|2017-04-27|2388.77  |-1  | 0 | 1 |1.0|1 |1.0  | \n",
    "|2017-04-28| 2384.20  | 1  | 0 | 1 |1.0| NA |1.0  |\n",
    "  \n",
    "*p_1* - is the prediction of the market behavior, derived from the supervised learning predictive model (e.g., Decision Tree as set by the *model* parameter below) and can be used as a trading signal (buy or sell) for the next trading day. For example, at the end of the trading day, say Monday, April 24, 2017, *p_1* = +1, because the *close_price* at Tuesday, April 25, 2017 is predicted to be greater than at Monday close. On Tuesday, April 25, 2017 *p_1* = -1 since the *close_price* at Wednesday close is predicted to be less than or equal to Tuesday close. The predictor *p_1* is the same as *p_n* (n days into the future) but shifted (Python *shift*) to the Python dataframe row for \"today.\" *p* is the same as *p_1* shifted forward by 1 day so as to align the prediction to the day corresponding to the prediction. For trading purposes *p_1* predictor can be utilized as a predictor for the next day.\n",
    "<br><br> \n",
    "\n",
    "There are several model variations including hybrid supervised learning and heuristic models. These are discussed in more detail in Section VI. \"Backtest.\"\n",
    "\n",
    "### Model Performance (Confusion Matrix)\n",
    "\n",
    "The classification model prediction (\"classification\") performance is summarized in a confusion matrix. The actual total market up or down days are listed in the first column. The rows list the actual prediction results as a percentage of the totals. The result here are for a Decision Tree classifiatier over the period January 1, 2000 to April 28, 2017. If we conser\n",
    "\n",
    "|Actuals\t| Predicted MktDown\t| Predicted MktUp |\n",
    "|:-----|-----------|---------|\n",
    "|Market Down days\t1660|\t0.749398|\t0.250000|\n",
    "|Market Up  days 2655|\t0.202637|\t0.797363|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "2016-01-04\n",
      "2017-01-03\n",
      "\n",
      "vltyw = 120 , maw = 60\n",
      "output filename = dfclfm_sp_nd43_2016_2017428_DT.csv\n",
      "model = DT \n",
      "test start date: 2016-01-01 00:00:00 \n",
      "test end date: 2017-04-28 00:00:00\n",
      "\n",
      "Price and Market Variables             close_price  vol_y_120   mucdown  mdcup  close_pricer_ma60\n",
      "2017-04-24  2374.149902   0.077694  0.009103    0.0           0.000563\n",
      "2017-04-25  2388.610107   0.078036  0.003068    0.0           0.000679\n",
      "2017-04-26  2387.449951   0.077238  0.003552    0.0           0.000771\n",
      "2017-04-27  2388.770020   0.076448  0.003001    0.0           0.000795\n",
      "2017-04-28  2384.199951   0.076150  0.004908    0.0           0.000758\n",
      "\n",
      "Predictor signals\n",
      "             t_n  p_n    p  t_1  p_1    v  mc2025  mc2025p  mc2025v  mc2025pv\n",
      "2017-04-24  1.0  0.0  1.0    1  1.0  1.0     1.0      1.0      1.0       1.0\n",
      "2017-04-25  1.0  0.0  1.0    1 -1.0  1.0     1.0      1.0      1.0       1.0\n",
      "2017-04-26  1.0  0.0 -1.0    1  1.0  1.0     1.0      1.0      1.0       1.0\n",
      "2017-04-27  1.0  0.0  1.0    1  1.0  1.0     1.0      1.0      1.0       1.0\n",
      "2017-04-28  1.0  0.0  1.0  NaN  1.0  1.0     1.0      1.0      1.0       1.0\n",
      "\n",
      "error_rate = 0.3813813813813814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Totals</th>\n",
       "      <th>Predicted MktDown</th>\n",
       "      <th>Predicted MktUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual MktDown</th>\n",
       "      <td>57</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual MktUp</th>\n",
       "      <td>233</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.716738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Totals  Predicted MktDown  Predicted MktUp\n",
       "actual MktDown      57           0.684211         0.298246\n",
       "actual MktUp       233           0.283262         0.716738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  V. Training and Prediction\n",
    "#   Features          X = dfML.loc[train_s:test_e]\n",
    "#   Labels            Y = dfT.loc[train_s:train_e]\n",
    "#   Train/Predict     mClfTrainTest() classifier training and prediction.\"fit\" classifier from test_s date to test_e\n",
    "#                      Make one prediction per date, looking ahead by ndays and save in order to compare later to labels.\n",
    "#                      dftr DataFrame\n",
    "#   Volatility & MA   Compute volatility and moving averages heuristic model.\n",
    "#   Save              save DataFrame \"dftr\" training results from t := train_s:train_e\n",
    "#   Confusion Matrix  Compute and print confusion matrix\n",
    "#   Plot              Training summary vs. nday\n",
    "\n",
    "%run algosciquant\n",
    "\n",
    "# Model Training and Prediction\n",
    "model='DT' #\n",
    "X = dfML.loc[train_s:,dfML.columns]\n",
    "Y = dfT.loc[train_s:test_e]\n",
    "print(\"...\")\n",
    "dfTR,clf = mktClfTrainTest(X,Y,nday,train_s,test_s,test_e,model,v=1)\n",
    "\n",
    "# Volatility and MovingAverage Predictors  \n",
    "mc_mcvariable='mc'+mcvariable\n",
    "vltyw='120'; maw='60'\n",
    "dfTR=volatilityPriceSP(dfTR,vltyw,maw,mcvariable=mc_mcvariable)\n",
    "print(\"vltyw =\",vltyw,\", maw =\",maw)\n",
    "\n",
    "# Save Predictions Data Frame (dfTR)\n",
    "tick='sp'\n",
    "str_test_e=str(test_e.year)+str(test_e.month)+str(test_e.day)\n",
    "str_test_syr=str(test_s.year)\n",
    "save_dtr_filename='dfclfm_'+tick+'_nd'+str(nday)+'_'+str_test_syr+'_'+str_test_e+'_'+model+'.csv'\n",
    "print('output filename =',save_dtr_filename)\n",
    "dfTR.to_csv(save_dtr_filename)\n",
    "\n",
    "# Print training results\n",
    "print('model =',model, '\\ntest start date:',test_s,'\\ntest end date:',test_e)\n",
    "print('\\nPrice and Market Variables',dfTR[['close_price','vol_y_'+vltyw,'mucdown','mdcup','close_pricer_ma'+maw]].tail(5))\n",
    "print('\\nPredictor signals\\n',dfTR[['t_n','p_n','p','t_1','p_1','v',mc_mcvariable,mc_mcvariable+'p',mc_mcvariable+'v',mc_mcvariable+'pv']].tail(5))\n",
    "\n",
    "# Plot Train Summary\n",
    "plot_train_summary=0\n",
    "if plot_train_summary==1:\n",
    "    rcParams['figure.figsize'] = 12, 3\n",
    "    dftrainsummary = pd.read_csv('./data_jupyter_notebook/df_sp_trainsummary.csv',index_col=0,parse_dates=True)\n",
    "    dftrainsummary[['S&P_rf_accuracy','S&P_dt_accuracy']].plot(use_index=True,grid=True)\n",
    "    plt.xlim(1,60), plt.ylim(0.3,1), plt.savefig('mc_tr_summary.png')\n",
    "\n",
    "# Confusion Matrix \"p\"\n",
    "\n",
    "(samplesize, errors, correct, er, dfCMA, dfCMR)=mktPredConfusionMatrix(dfTR,\"t\",'p')\n",
    "\n",
    "print('\\nerror_rate =',er)\n",
    "dfCMR[['Totals','Predicted MktDown','Predicted MktUp']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Backtest\n",
    "\n",
    "### Strategies\n",
    "\n",
    "We now test the trade performance of our models generated in the previous section (Section V. Model Training and Prediction). The predictors are listed below along with a brief description. \n",
    "\n",
    "* **p_dt** - Decision tree predictive model. Market up prediciton (buy) *p_dt* = +1, or market down prediction (sell) *p_dt* = -1 signal.  \n",
    "<br>\n",
    "* **p_rf** -  Random Forest predictive model. Market up prediction (buy) *p_dt* = +1, or market down (sell) *p_dt* = -1 signal generated by.  \n",
    "<br>\n",
    "* **pv_dt** - This model is a combination of decision tree predictive model and heuristics based on yearly volatility measure and moving average. If the volatility, derived based on trailing 120 days is greater than 20 percent and trailing 60 day price moving average is negative then *pv_dt* = -1, otherwise *pv_dt* = *p_dt*. In summary, if the volatility is high with a downward trend then sell, otherwise trade based on a decision tree predictive model (*p_dt*).  \n",
    "<br>\n",
    "* pv_rf - adlfjs  \n",
    "<br>\n",
    "* mc2025 - aldfs  \n",
    "<br>\n",
    "* mc2025v - asfdsjf  \n",
    "<br>\n",
    "* mc2025pv_dt - adf;sa  \n",
    "<br>\n",
    "* mc2025pv_rf - adf;sa  \n",
    "\n",
    "\n",
    "\n",
    "### Backtesting Results\n",
    "\n",
    "Back testing starting January 1, 2000, close_price on December 31, 1999 is $1469.25. Here we first give a brief description of each strategy and then summarize the results in the table below.\n",
    "\n",
    "\n",
    "This period (Jan 1, 2000 to Apr 28, 2017) includes two Bear markets and serves as a good test for the strategies. The heuristic strategy mc2025v performs very close to the top performing model mc2025pv_rf. In the next seection, we graph the performance \n",
    "Table: Backtest summary, from January 1, 2000 to April 28, 2017.\n",
    "\n",
    "|Strategy| End Value  |Total Rturn| Annualized Return |\n",
    "|--------|----------- |------------|------------------|\n",
    "|S&P 500 | \\$2384.2   |63.84% | 2.89% |\n",
    "|p_dt | \\$2441.8 | 66.2% | 2.97% |\n",
    "|p_rf | \\$3417.87 | 132.6% | 5%|\n",
    "|pv_dt| \\$3385.06 | 130.39% |  4.93%\n",
    "|pv_rf | \\$3627.18 | 146.8% | 5.35%|\n",
    "|mc2025  | \\$4208.40  |186.4% | 6.26% \n",
    "|mc2025v | \\$4674     |218.1% |6.96% |\n",
    "|mc2025pv_dt| \\$4377.14| 197.92% | 6.5% |\n",
    "|mc2025pv_rf| \\$4690.2| 219.2% | 6.92% | \n",
    "\n",
    "\n",
    "### Backtest Performance Graphs\n",
    "\n",
    "Backtest from 1970 \n",
    "\n",
    "![sdfsdfasdfsa](./mc_1970_20170428.png)\n",
    "\n",
    "Backtest from 2000\n",
    "\n",
    "![sdfsdfasdfsa](./mc_2000_20170428.png)\n",
    "\n",
    "Backtest 1980 - 1990\n",
    "\n",
    "![sdfsdfasdfsa](./mc_1980_19891231.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Results\n",
    "* We learn that basic machine prediction supplemented with heuristics provides improved financial return vs. S&P 500. Based on the data analysis, we gain many insights about the market, which as expected are consistent with basic market theory.\n",
    "* Models studied here provide down-side protection and benefit from market up trends\n",
    "* There are many improvements that can be made to the approach discussed here, such as feature selection, class labels and associated trading strategy, however such improvements go beyond the scope of this exercise. \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Code optimization\n",
    "Other articles - stock prediction \n",
    "Application to other indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "strategy trade variable =  mc2025v ,bt_startyear 2000 \n",
      "end date, 2017-04-28 00:00:00\n",
      "model =  RF , nday =  43 , ma =  60 , vltyw =  120\n",
      "dft filename = dft_sp_nd43_mc2025v_2000_2017428_RF.csv\n",
      "\n",
      "Annualized Returns\n",
      "                 nyear        Rc  Rc_strat        Ra  Ra_strat\n",
      "2017-04-28  17.334247  0.638378  2.211884  0.028891  0.069633\n",
      "\n",
      "Yearly Trade Summary\n",
      "       start_price  end_close_price  end_close_price_SP    return  return_SP\n",
      "2000  1455.219971      1283.270020         1235.734139 -0.118161  -0.150827\n",
      "2001  1283.270020      1148.079956         1294.886003 -0.105348   0.047868\n",
      "2002  1154.670044       879.820007         1294.886003 -0.238033   0.000000\n",
      "2003   909.030029      1111.920044         1481.956549  0.223194   0.144469\n",
      "2004  1108.479980      1211.920044         1615.235606  0.093317   0.089935\n",
      "2005  1202.079956      1268.800049         1691.044740  0.055504   0.046934\n",
      "2006  1268.800049      1416.599976         1888.031089  0.116488   0.116488\n",
      "2007  1416.599976      1468.359985         1954.077858  0.036538   0.034982\n",
      "2008  1447.160034       903.250000         1796.019312 -0.375847  -0.080887\n",
      "2009   931.799988      1115.099976         2338.121202  0.196716   0.301835\n",
      "2010  1132.989990      1257.640015         2730.965525  0.110019   0.168017\n",
      "2011  1271.869995      1277.060059         2492.967899  0.004081  -0.087148\n",
      "2012  1277.060059      1426.189941         2784.086556  0.116776   0.116776\n",
      "2013  1462.420044      1848.359985         3608.210966  0.263905   0.296012\n",
      "2014  1831.979980      2058.899902         4019.209063  0.123866   0.113906\n",
      "2015  2058.199951      2043.939941         3990.005501 -0.006928  -0.007266\n",
      "2016  2012.660034      2257.830078         4426.261336  0.121814   0.109337\n",
      "2017  2257.830078      2384.199951         4673.997465  0.055970   0.055970\n"
     ]
    }
   ],
   "source": [
    "# BackTest Code\n",
    "%run algosciquant\n",
    "\n",
    "# Strategy Trade\n",
    "readfile=1\n",
    "predictor='mc2025v' # 'p', 'v, 'pv', mc_mcvariable+'v', mcvariablepv, mcvariablep\n",
    "                    # 'mc2025', 'mc2025v', 'mc2025pv'\n",
    "bt_summary_graphs=0\n",
    "\n",
    "# Read File\n",
    "price_variable='close_price'\n",
    "if readfile==1:\n",
    "    bt_model='RF' # RF or DT\n",
    "    bt_startyear='2000' # 1952 DT, 1970 DT and RF, 1980 DT and RF, 1990 DT and RF, 2000 DT and RF\n",
    "    bt_test_s=dt.datetime(int(bt_startyear),1,1)\n",
    "    bt_test_e=dt.datetime(2017,4,28)\n",
    "    str_bt_test_e=str(bt_test_e.year)+str(bt_test_e.month)+str(bt_test_e.day)\n",
    "    dfTR_fn='./data_jupyter_notebook/dfclfm_sp_nd43_'+bt_startyear+'_'+str_bt_test_e+'_'+bt_model+'.csv'\n",
    "    dfTR2 = pd.read_csv(dfTR_fn,index_col=0,parse_dates=True)\n",
    "    bt_nday=43;bt_vltyw=120; bt_maw=60;\n",
    "else:\n",
    "    bt_test_s=test_s\n",
    "    bt_test_e=test_e\n",
    "    bt_model=model;bt_nday=nday; bt_vltyw=vltyw; bt_maw=maw; bt_startyear=str(test_s.year)\n",
    "    dfTR2=dfTR\n",
    "\n",
    "print('...')\n",
    "\n",
    "# Backtest\n",
    "(dftsummary,dfreturns)=backTestSummary(dfTR2,dfsp,price_variable,predictor,bt_test_s,bt_test_e)\n",
    "\n",
    "# Save backtest trade summary \"dft\" dataframe\n",
    "ticker='sp'\n",
    "str_test_syr=str(test_s.year)\n",
    "str_=str(test_e.year)+str(test_e.month)+str(test_e.day)\n",
    "save_dft_filename='dft_'+ticker+'_nd'+str(bt_nday)+'_'+str(predictor)+'_'+bt_startyear+'_'+str_+'_'+bt_model+'.csv'\n",
    "dft.to_csv(save_dft_filename)\n",
    "\n",
    "\n",
    "# Print context variables\n",
    "print('strategy trade variable = ',predictor,',bt_startyear',bt_startyear,'\\nend date,',test_e)\n",
    "print('model = ',bt_model,', nday = ',bt_nday,', ma = ',bt_maw,', vltyw = ',bt_vltyw)\n",
    "print('dft filename =',save_dft_filename)\n",
    "\n",
    "\n",
    "# Annualized Returns\n",
    "print(\"\\nAnnualized Returns\\n\",dfreturns[['nyear','Rc','Rc_strat','Ra','Ra_strat']])\n",
    "\n",
    "bt_summary_print=1\n",
    "if bt_summary_print==1:\n",
    "    print('\\nYearly Trade Summary\\n',dftsummary[['start_price','end_close_price','end_close_price_SP','return','return_SP']])\n",
    "\n",
    "# Plot\n",
    "bt_summary_graphs=0\n",
    "if bt_summary_graphs==1:\n",
    "    files=[\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+bt_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_mc2025pv_'+bt_startyear+'_2017428_RF.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_mc2025_'+bt_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_pv_'+bt_startyear+'_2017428_RF.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+bt_startyear+'_2017428_RF.csv',  \n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+bt_startyear+'_2017428_DT.csv'\n",
    "    ]\n",
    "    lnames=['close_price','mc2025pv_rf','mc2025','pv_rf','p_rf','p_dt']\n",
    "    fig = plt.figure()\n",
    "    rcParams['figure.figsize'] = [12,4]\n",
    "    normalized_plot_from_files(fig,bt_startyear,bt_test_e,files,lnames,plot_variable='close_price',nsubplot=111,ncol=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BackTest Summary Graphs\n",
    "%run algosciquant\n",
    "\n",
    "graph = 0 \n",
    "if graph == 1:\n",
    "    g_startyear='1970' # 1970, 1980, 1990, 2000\n",
    "    s = dt.datetime(1970,1,1)\n",
    "    e = dt.datetime(2017,4,28)\n",
    "    s=dt.datetime(int(g_startyear),1,1)\n",
    "    #e =dt.datetime(1989,12,31)\n",
    "    rcParams['figure.figsize'] = 12, 2.5\n",
    "    # Plot 1\n",
    "    files1=[\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_mc2025pv_'+g_startyear+'_2017428_RF.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_mc2025_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_pv_'+g_startyear+'_2017428_RF.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_RF.csv',  \n",
    "     './data_jupyter_notebook/dft_sp_nd43_v_'+g_startyear+'_2017428_DT.csv'\n",
    "    ]\n",
    "\n",
    "    lnames1=['close_price','mc2025pv_rf','mc2025' ,'pv_rf','p_rf','v']\n",
    "    price_variable='close_price'\n",
    "    fig1 = plt.figure()\n",
    "    normalized_plot_from_files(fig1,s,e,files1,lnames1,price_variable,nsubplot=111,sfig=1,sfigname='mc_1970_20170428.png') \n",
    "\n",
    "    # plot 2\n",
    "    fig2 = plt.figure()\n",
    "    s=dt.datetime(2000,1,1)\n",
    "    e=dt.datetime(2017,4,28)\n",
    "    normalized_plot_from_files(fig2,s,e,files1,lnames1,price_variable,nsubplot=111,sfig=1,sfigname='mc_2000_20170428.png') \n",
    "\n",
    "    # plot 3\n",
    "    s=dt.datetime(1980,1,1)\n",
    "    e=dt.datetime(1989,12,31)\n",
    "    fig3 = plt.figure()\n",
    "    files3=[\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_mc2025_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_pv_'+g_startyear+'_2017428_RF.csv' \n",
    "    ]\n",
    "    lnames3=['close_price','mc2025','pv_rf']\n",
    "    normalized_plot_from_files(fig3,s,e,files3,lnames3,price_variable,nsubplot=111,sfig=1,sfigname='mc_1980_19891231.png') \n",
    "\n",
    "    # plot 4\n",
    "    fig4 = plt.figure()\n",
    "    s = dt.datetime(1970,1,1)\n",
    "    e = dt.datetime(2017,4,28)\n",
    "    files4=[\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_pv_'+g_startyear+'_2017428_DT.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_pv_'+g_startyear+'_2017428_RF.csv',  \n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_RF.csv',\n",
    "     './data_jupyter_notebook/dft_sp_nd43_p_'+g_startyear+'_2017428_DT.csv'\n",
    "    ]\n",
    "\n",
    "    lnames4=['close_price','pv_dt','pv_rf','p_rf','p_dt']\n",
    "    normalized_plot_from_files(fig4,s,e,files4,lnames4,price_variable,nsubplot=111,sfig=1,sfigname='mc_1970_20170428_p.png') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
